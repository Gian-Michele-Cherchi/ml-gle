import os 
import numpy as np
import torch
from scipy.fftpack import dct, idct
import logging
import time 
import yaml
import sys 
import gc
import tqdm
import argparse
import re
with open("config.yaml") as f:
    config = yaml.load(f, Loader=yaml.FullLoader)

PROJECTNAME = config["PROJECTNAME"]
USERPATH = config["USERPATH"]
SYSTEM = config["SYSTEM"]
FULLPATH  = os.path.join(USERPATH, PROJECTNAME)
SUBMODULE = os.path.join(FULLPATH, "ia")
SAVEPATH = os.path.join(FULLPATH, "save")
sys.path.append(SUBMODULE)
logging.basicConfig(level=logging.INFO)


def modes_to_monomers (dataset: torch.tensor,  
                      savepath: str,
                      n_out: int,
                      modes_norms: list=None, 
                      fill: str=None,
                      normalization: str=None,
                      device: str="cpu",
                      save: bool=True,
                      overwrite: bool=False,
                      ):
    """
    Transforms modes coordinates to monomer coordinates positions

    INPUT:
    - dataset [tensor]: dataset containing the modes dynamics for all polymers with size [npol, nframes, nmodes, 3] 
    - n_out [int]: number of nodes to reconstruct 
    - savepath: filepath for the output tensor 

    OUTPUT:
    - positional tensor with size [npol, nframes, n_out, 3] 
    """
    if len(dataset.shape) != 4 or dataset.shape[3] != 3:
        raise ValueError("Input tensor must have size [npol, nframes, nmodes, 3]")
    
    npol, nframes, nmodes, _ = dataset.shape

    #filename = "gen_pos_data_"+str(temp)+"_nmon"+str(n_out)+"_.pt"
    #savepath = os.path.join(savepath, filename)

    
    if fill == "Normal":
        fill_n = n_out - nmodes
        assert fill_n != 0, ValueError("The dimensions to fill should not be zero. Please enter a new suiteed reconstruction dimension.")
        fill_dataset = torch.randn_like(dataset[:,:,0,:].unsqueeze(2).expand(-1,-1,fill_n,-1)).to(device)
        fill_dataset = torch.mul(fill_dataset, modes_norms[None, None,nmodes+1:n_out+1, None].expand(npol, nframes,-1,3))
        dataset = torch.cat([dataset,fill_dataset], dim=2)

    # Overwrite the saved positional dataset
    if overwrite:
        dataset_pos = idct(dataset.cpu().numpy(), type=2, axis=2, n=n_out, norm=normalization)
        torch.save(torch.tensor(dataset_pos).to(device), savepath)
    

    if not os.path.isfile(savepath):
        # polymer effective dynamics configurations reconstruction 
        dataset_pos = idct(dataset.cpu().numpy(), type=2, axis=2, n=n_out, norm=normalization)
        if save:
            torch.save(torch.tensor(dataset_pos).to(device), savepath)
    else:
        dataset_pos = torch.load(savepath, map_location=device)
        print("File already exists. Override to discard and re-compute the reconstruction.")

    return torch.tensor(dataset_pos).to(device)
    


def save_tensor_to_xyz(tensor: torch.tensor, 
                       output_filepath: str,
                       ):
    """
    Save a PyTorch tensor to a file in .xyz format.

    Parameters:
    - tensor [torch.tensor]: PyTorch tensor with size [npol, nframes, n, 3]
    - output_file [string]: Output file path (including the .xyz extension)
    """
    # Check if the input tensor has the correct size
    if len(tensor.shape) != 4 or tensor.shape[3] != 3:
        raise ValueError("Input tensor must have size [npol, nframes, n, 3]")

    # Get the dimensions
    npol, nframes, n, _ = tensor.shape

    # Reshape the tensor for saving
    reshaped_tensor = tensor.permute(2, 0, 1, 3).contiguous().view(-1, 3)

    # Create the content string for the .xyz file
    content = f"{n * npol * nframes}\n"
    content += "Generated by PyTorch\n"

    for i in range(n * npol * nframes):
        content += f"{reshaped_tensor[i][0]} {reshaped_tensor[i][1]} {reshaped_tensor[i][2]}\n"
    
    # Save to file
    with open(output_filepath, "w") as f:
        f.write(content)


if __name__ == "__main__":
    
    N_TRAIN = 1000
    INPUT_SEQ = 128
    NGEN = 100000 + INPUT_SEQ
    
    
    parser = argparse.ArgumentParser()
    parser.add_argument('--temp', type=int, default=300)
    parser.add_argument('--nmonomers', type=int, default=1, required=True)
    parser.add_argument('--savepath', type=str, required=False, default="save/melt/temp")
    parser.add_argument('--fill', type=str, required=False, default=None)
    parser.add_argument('--device', type=str, required=False, default="cpu")
    parser.add_argument('--save', type=str, required=False, default="True")
    
    # Argument parser
    args = parser.parse_args()
    savepath = args.savepath
    temp = args.temp
    nmon = args.nmonomers
    device = args.device
    save = args.save
    fill = args.fill
    #savepath = "save/melt/temp"
    #temp = 300
    #device="cpu"
    #save=True

    rel_savepath = os.path.join(FULLPATH, savepath)
    com_path = os.path.join(rel_savepath, "T"+str(temp)+"/gen_data") # C.o.M gen data path
    modes_path =  os.path.join(rel_savepath, "T"+str(temp)+"/gen_data/long") # gen modes path
    savepath = os.path.join(savepath, "T"+str(temp)+"/gen_data/reconstructed") # gen pos data savepath
    
    modes_filenames = os.listdir(modes_path)
    sorted_filenames = sorted(modes_filenames, key=lambda x: int(re.split('(\d+)', x.split('_')[2])[1]))

    k = len(sorted_filenames)
    #nmon = k+1

    assert nmon >= k+1, ValueError("The number of monomers should be equal or above the number of generated modes.")

    dataset = torch.load(os.path.join(FULLPATH, "data/melt/temp/ready/modesdata_T"+str(temp)+"_.pt"), map_location=device).swapaxes(0,1)[:,5000:,:,:]
    norm = [torch.sqrt((dataset[:,:N_TRAIN]**2).mean(dim=(0,1,3))),torch.sqrt((dataset[:,:N_TRAIN].diff(dim=1)**2).mean(dim=(0,1,3)))]
    npol = dataset.size(0)
    
    # gen modes dataset
    gen_modes = torch.zeros(3*npol,NGEN, k+1,3, device=device)
    for nmode, filename in enumerate(sorted_filenames):
            sigma_z = torch.tensor(norm[0][nmode+1].item(),device=device)
            gen_modes[:,:,nmode+1,:] =  sigma_z*torch.load(os.path.join(modes_path, filename), map_location=device)[:,:NGEN,0,:]
    
    # gen c.o.m. data 
    gen_modes[:,:,0,:] = torch.load(os.path.join(com_path, "gen_com_data_.pt"), map_location=device)
    logging.info("\n")
    logging.info("[Gen modes data and CoM loaded.]\n")
    
    pos_filename = "gen_pos_data_"+str(temp)+"_nmon"+str(nmon)+"_.pt"
    pos_filepath = os.path.join(savepath, pos_filename)
    # Modes data to monomer configuration 
    dataset_pos = modes_to_monomers (gen_modes,  
                                    savepath=pos_filepath,
                                    n_out=nmon, 
                                    modes_norms=norm[0],
                                    fill=fill,
                                    device=device,
                                    save=save,
                                    )
    if save:
        logging.info("[Gen positional data created and saved to "+pos_filepath+"]\n")
    
    # Convert pos conf data to .xyz format
    save_tensor_to_xyz(dataset_pos, savepath)

